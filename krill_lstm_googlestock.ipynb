{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "krill_lstm_googlestock.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPoPr/L9FIA/1RPDtJF0XgR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arshadshk/Deep-Learning-with-TensorFlow/blob/master/krill_lstm_googlestock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NCMggH9wmII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Google stock price\n",
        "\n",
        "# predicting the movenet as upward or downward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIvQPCb0xe2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import plotly.express as pt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIWJBTn_xxcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_tr = pd.read_csv('Google_Stock_Price_Train.csv')\n",
        "df_test = pd.read_csv('Google_Stock_Price_Test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8_Ol-ZTx45-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "6077d433-8d5d-4612-9e7a-5edb52576fdb"
      },
      "source": [
        "df_tr.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/3/2012</td>\n",
              "      <td>325.25</td>\n",
              "      <td>332.83</td>\n",
              "      <td>324.97</td>\n",
              "      <td>663.59</td>\n",
              "      <td>7,380,500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/4/2012</td>\n",
              "      <td>331.27</td>\n",
              "      <td>333.87</td>\n",
              "      <td>329.08</td>\n",
              "      <td>666.45</td>\n",
              "      <td>5,749,400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/5/2012</td>\n",
              "      <td>329.83</td>\n",
              "      <td>330.75</td>\n",
              "      <td>326.89</td>\n",
              "      <td>657.21</td>\n",
              "      <td>6,590,300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/6/2012</td>\n",
              "      <td>328.34</td>\n",
              "      <td>328.77</td>\n",
              "      <td>323.68</td>\n",
              "      <td>648.24</td>\n",
              "      <td>5,405,900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/9/2012</td>\n",
              "      <td>322.04</td>\n",
              "      <td>322.29</td>\n",
              "      <td>309.46</td>\n",
              "      <td>620.76</td>\n",
              "      <td>11,688,800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Date    Open    High     Low   Close      Volume\n",
              "0  1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
              "1  1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
              "2  1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
              "3  1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
              "4  1/9/2012  322.04  322.29  309.46  620.76  11,688,800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfEjP0O7x-IG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pt.line( df_test,   x='Date', y='Open')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGUVczIOyICU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9452d140-f7db-4df5-8d98-ee83cdd4923c"
      },
      "source": [
        "# pd column to numpy array\n",
        "\n",
        "training_set = df_tr.iloc[:,1:2].values\n",
        "print(training_set.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1258, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2z-K17XzvZJ",
        "colab_type": "text"
      },
      "source": [
        "## Feature scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-MKeyE0zkrW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b29f498-fdc1-4e2a-9570-e61a282349e7"
      },
      "source": [
        "\"\"\"\n",
        "standardixzation  =  x - mean /  std\n",
        "\n",
        "normalization = x -min / max - min\n",
        "\n",
        "RNN , if  sigmoid in output ot is recommended to use normalization\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.preprocessing  import MinMaxScaler\n",
        "\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_set_scaled = sc.fit_transform(training_set)\n",
        "print(training_set_scaled[0:5,0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.08581368 0.09701243 0.09433366 0.09156187 0.07984225]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex9u_XcI1mmt",
        "colab_type": "text"
      },
      "source": [
        "## Creating a datastructure for RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoEpYB_51KHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### AUthor tried different timestamps and got 60 gives best results."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKlQix0r1TdA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ca942cc-811f-4228-ac77-c8ef21a94701"
      },
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in range(60,len(training_set_scaled)):\n",
        "  X_train.append(training_set_scaled[i-60:i,0])\n",
        "  y_train.append(training_set_scaled[i,0])\n",
        "\n",
        "# list fo array\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "print(X_train.shape,y_train.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1198, 60) (1198,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzddKHaF4JDm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e65691c-81dd-4fbb-bbc1-c7f37259233e"
      },
      "source": [
        "# Rehsaping the data  For keras input\n",
        "X_train = np.reshape(X_train  ,(X_train.shape[0], X_train.shape[1],1))\n",
        "print(X_train.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1198, 60, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPBZTJYU9c1I",
        "colab_type": "text"
      },
      "source": [
        "## Model building_ stacked RNN with droupout regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXOPIuLB4K45",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "0946fd25-9aad-4341-b24e-010b5547c895"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYPlA5x190Yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing the RNN\n",
        "regressor = Sequential()\n",
        "\n",
        "# Adding layers\n",
        "regressor.add(LSTM(units = 50 , return_sequences = True, input_shape = (X_train.shape[1],1)))\n",
        "regressor.add(Dropout(0.2))\n",
        "regressor.add(LSTM(units = 50 , return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "regressor.add(LSTM(units = 50 ))\n",
        "regressor.add(Dropout(0.2))\n",
        "regressor.add(Dense(units = 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Csj_jjd9_-We",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "6c0095a6-3359-40fa-85a6-d9a40c8403ab"
      },
      "source": [
        "# Compiling the model\n",
        "regressor.compile(optimizer='adam', loss = 'mean_squared_error')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBMzB_CgB-cP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "88a68e06-bb07-4e0a-f902-abc9b849d2d3"
      },
      "source": [
        "# Fitting the model to the trainingset\n",
        "regressor.fit(X_train , y_train, epochs=100 , batch_size=32 )"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "1198/1198 [==============================] - 19s 15ms/step - loss: 0.0435\n",
            "Epoch 2/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0055\n",
            "Epoch 3/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0051\n",
            "Epoch 4/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0049\n",
            "Epoch 5/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0051\n",
            "Epoch 6/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0039\n",
            "Epoch 7/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0035\n",
            "Epoch 8/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0040\n",
            "Epoch 9/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0043\n",
            "Epoch 10/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0040\n",
            "Epoch 11/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0038\n",
            "Epoch 12/100\n",
            "1198/1198 [==============================] - 10s 8ms/step - loss: 0.0034\n",
            "Epoch 13/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0035\n",
            "Epoch 14/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0035\n",
            "Epoch 15/100\n",
            "1198/1198 [==============================] - 10s 8ms/step - loss: 0.0033\n",
            "Epoch 16/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0035\n",
            "Epoch 17/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0036\n",
            "Epoch 18/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0035\n",
            "Epoch 19/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0035\n",
            "Epoch 20/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0031\n",
            "Epoch 21/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0030\n",
            "Epoch 22/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0028\n",
            "Epoch 23/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0028\n",
            "Epoch 24/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0033\n",
            "Epoch 25/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0028\n",
            "Epoch 26/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0028\n",
            "Epoch 27/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0028\n",
            "Epoch 28/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0028\n",
            "Epoch 29/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0030\n",
            "Epoch 30/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0025\n",
            "Epoch 31/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0027\n",
            "Epoch 32/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0026\n",
            "Epoch 33/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0025\n",
            "Epoch 34/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0029\n",
            "Epoch 35/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0025\n",
            "Epoch 36/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0029\n",
            "Epoch 37/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0027\n",
            "Epoch 38/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0024\n",
            "Epoch 39/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0025\n",
            "Epoch 40/100\n",
            "1198/1198 [==============================] - 10s 8ms/step - loss: 0.0024\n",
            "Epoch 41/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0023\n",
            "Epoch 42/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0025\n",
            "Epoch 43/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0024\n",
            "Epoch 44/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0024\n",
            "Epoch 45/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0023\n",
            "Epoch 46/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0021\n",
            "Epoch 47/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0024\n",
            "Epoch 48/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0021\n",
            "Epoch 49/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0023\n",
            "Epoch 50/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0022\n",
            "Epoch 51/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0022\n",
            "Epoch 52/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0019\n",
            "Epoch 53/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0020\n",
            "Epoch 54/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0021\n",
            "Epoch 55/100\n",
            "1198/1198 [==============================] - 9s 7ms/step - loss: 0.0019\n",
            "Epoch 56/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0018\n",
            "Epoch 57/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0020\n",
            "Epoch 58/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0019\n",
            "Epoch 59/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0020\n",
            "Epoch 60/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0018\n",
            "Epoch 61/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0018\n",
            "Epoch 62/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0019\n",
            "Epoch 63/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0017\n",
            "Epoch 64/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0018\n",
            "Epoch 65/100\n",
            "1198/1198 [==============================] - 9s 7ms/step - loss: 0.0019\n",
            "Epoch 66/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0018\n",
            "Epoch 67/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0018\n",
            "Epoch 68/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0020\n",
            "Epoch 69/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0017\n",
            "Epoch 70/100\n",
            "1198/1198 [==============================] - 10s 8ms/step - loss: 0.0017\n",
            "Epoch 71/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0015\n",
            "Epoch 72/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0015\n",
            "Epoch 73/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0017\n",
            "Epoch 74/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0017\n",
            "Epoch 75/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0017\n",
            "Epoch 76/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0017\n",
            "Epoch 77/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0017\n",
            "Epoch 78/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0015\n",
            "Epoch 79/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0015\n",
            "Epoch 80/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0014\n",
            "Epoch 81/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0015\n",
            "Epoch 82/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0016\n",
            "Epoch 83/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0015\n",
            "Epoch 84/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0015\n",
            "Epoch 85/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0015\n",
            "Epoch 86/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0014\n",
            "Epoch 87/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0014\n",
            "Epoch 88/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0015\n",
            "Epoch 89/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0014\n",
            "Epoch 90/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0013\n",
            "Epoch 91/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0013\n",
            "Epoch 92/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0015\n",
            "Epoch 93/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0013\n",
            "Epoch 94/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0014\n",
            "Epoch 95/100\n",
            "1198/1198 [==============================] - 9s 7ms/step - loss: 0.0013\n",
            "Epoch 96/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0013\n",
            "Epoch 97/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0012\n",
            "Epoch 98/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0012\n",
            "Epoch 99/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0013\n",
            "Epoch 100/100\n",
            "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0012\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9100db8048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQEima-MIRks",
        "colab_type": "text"
      },
      "source": [
        "## Making the predictions and vizualizing the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgJXu4kXC32X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_stock_price = df_test.iloc[:,1:2].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjQNeARBLiS0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8fada12-7b84-4518-e79c-09b6af939271"
      },
      "source": [
        "dataset_total = pd.concat( (df_tr['Open'],df_test['Open']) , axis= 0 )\n",
        "inputs = dataset_total[len(dataset_total) - len(df_test) - 60 : ].values\n",
        "inputs = inputs.reshape((-1,1))\n",
        "\n",
        "inputs = sc.transform(inputs)          ## scaling\n",
        "X_test = []\n",
        "for i in range(60, 80):\n",
        "  X_test.append(inputs[i-60:i , 0])\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "X_test= np.reshape(X_test, (X_test.shape[0] ,X_test.shape[1] , 1))\n",
        "print(X_test.shape[0])\n",
        "\n",
        "predicted_stock_price = regressor.predict(X_test)\n",
        "\n",
        "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouDDx2vmLict",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "7bc32b88-b85e-47fe-a50b-28bc706cab84"
      },
      "source": [
        "# vizualizing the results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(real_stock_price, color = 'red' ,label ='Real google stockprice' )\n",
        "plt.plot(predicted_stock_price, color = 'blue' ,label ='Predicted google stockprice' )"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f90914b0a20>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD5CAYAAADcDXXiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXAb6f2wz9O4YwAPmAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbQd2U35G5KN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import save_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApVB1zEEH93i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_model(regressor, 'gogle.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsEK9tzzJWFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}